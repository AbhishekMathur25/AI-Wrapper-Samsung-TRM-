# LLM Iterative Refinement Agent (Agno + Ollama)

This Python script implements an agentic workflow using the **Agno framework** to enhance the quality and reliability of answers generated by local Large Language Models (LLMs) served via **Ollama**. It simulates an iterative refinement process inspired by concepts like Samsung's TRM, using a **Draft -> Verify -> Refine -> Finalize** loop.

## Overview

Instead of taking the LLM's first answer, this workflow forces the model to:
1.  **Draft** an initial response.
2.  **Verify** its own draft for accuracy, logic, and completeness, assigning a confidence score.
3.  **Refine** the draft based on self-generated feedback if the confidence score is below a threshold.
4.  **Loop** steps 1-3 until the confidence threshold is met or a maximum number of attempts is reached.
5.  **Finalize** the verified draft into a polished answer.

This structured approach aims to improve the quality of responses compared to a single direct query to the LLM, particularly for tasks requiring reasoning or accuracy.

## Features

* **Iterative Refinement:** Automatically loops drafting and verification.
* **Self-Correction:** Uses LLM-generated feedback to improve drafts.
* **Confidence Scoring:** Employs the LLM to assess the quality of its own drafts.
* **Local LLM Support:** Integrates seamlessly with models running locally via Ollama.
* **Configurable:** Easily adjust the LLM model, confidence threshold, and maximum attempts.
* **Workflow Management:** Built using the Agno framework for clear step definition and execution.

## How it Works

The script defines an Agno `Workflow` consisting of:
1.  An **Iterative Loop (`Loop`)**:
    * **Draft Step (`draft_step`):** Calls the `assistant_agent` (powered by the Ollama LLM) to generate or refine an answer based on the user prompt and any previous feedback. Increments the attempt counter.
    * **Verify Step (`verify_step`):** Calls the `assistant_agent` with a specific prompt, asking it to evaluate the current draft, provide a confidence score (0.0-1.0), and generate feedback if needed. The response is expected in JSON format.
    * **End Condition (`check_confidence_condition`):** A function that checks the confidence score and attempt count from the `Verify Draft` step's output. It returns `True` (stop loop) if confidence >= `CONFIDENCE_THRESHOLD` or attempt >= `MAX_ATTEMPTS`, otherwise `False` (continue loop).
2.  A **Finalize Step (`finalize_step`):** Runs *after* the loop successfully completes. It takes the high-confidence draft and asks the `assistant_agent` to polish it into a final answer.

The `session_state` dictionary is used to pass information (like the current draft, feedback, and attempt count) between steps and loop iterations.

## Requirements

* **Python 3.8+**
* **Ollama:** Installed and running locally. [https://ollama.com/](https://ollama.com/)
* **Ollama Model:** The LLM specified in `OLLAMA_MODEL_ID` must be pulled (e.g., `ollama pull gemma3:4b`).
* **Python Libraries:**
    ```bash
    pip install agno ollama python-dotenv
    ```

## Configuration

You can modify these variables at the top of the script (`advance.py`):

* `OLLAMA_MODEL_ID`: The Ollama model tag to use (e.g., `"gemma3:4b"`, `"llama3:8b"`). **Using a more capable model (7B+) is highly recommended for better reasoning and JSON adherence.**
* `CONFIDENCE_THRESHOLD`: The minimum confidence score (0.0 to 1.0) required to stop the refinement loop.
* `MAX_ATTEMPTS`: The maximum number of draft/verify cycles before stopping, even if the threshold isn't met.
* `OLLAMA_TIMEOUT`: Timeout in seconds for requests to the Ollama model. Increase if your model/hardware is slow.

## Usage

1.  Ensure Ollama is running and the desired model is pulled.
2.  Modify the configuration variables in the script if needed.
3.  Change the `user_question` variable in the `if __name__ == "__main__":` block to your desired prompt.
4.  Run the script from your terminal:
    ```bash
    python advance.py
    ```

## Output

The script will print logs to the console showing:
* Which attempt (loop iteration) is running.
* The first 100 characters of the current draft.
* The confidence score and feedback from the verification step.
* Messages indicating whether the loop is stopping or continuing.
* A final, polished answer printed between separator lines (`===...===`).

## Customization

* **Prompts:** Modify the `draft_prompt` in `draft_step`, the `verify_prompt` in `verify_step`, or the `finalize_prompt` in `finalize_step` to change the agent's behavior or instructions. Improving the `verify_prompt` is key to better results.
* **Logic:** Adjust the Python code within the step functions or the `check_confidence_condition` function to alter the workflow logic.

## Notes & Limitations

* **Verification Reliability:** The effectiveness of the verification step heavily depends on the chosen LLM's ability to critically evaluate its own output and follow the JSON format instruction accurately. Smaller models may struggle with this.
* **JSON Parsing:** The script includes basic cleanup for JSON responses, but robust error handling might be needed if the LLM frequently outputs malformed JSON.
* **Prompt Engineering:** The quality of the prompts used in each step significantly impacts the final output. Experimentation is often required.
